Thông tin về model

Model: XGBoost (scikit-learn)

model = XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=6,
    random_state=42,
    n_jobs=-1,
    verbosity=0  # Không hiện log
)

Lưu mô hình bằng: joblib.dump(model, 'best_model.pkl')
Dataset: dataset1_qt 

param_grid = {
    'n_estimators': [200, 400, 600],            # Càng nhiều cây, càng ổn định (nhưng nặng hơn)
    'max_depth': [6, 8, 10, 12],                # Độ sâu lớn cho khả năng học tốt hơn
    'learning_rate': [0.01, 0.05, 0.1],         # Giảm tốc độ học để ổn định hơn
    'subsample': [0.7, 0.8, 1.0],               # Dropout row-wise để tránh overfit
    'colsample_bytree': [0.6, 0.8, 1.0],        # Dropout column-wise
    'reg_alpha': [0, 0.1, 0.5],                 # L1 regularization (giảm overfit)
    'reg_lambda': [1, 2, 5]                     # L2 regularization
}

xgb_model = XGBRegressor(
    objective='reg:squarederror',
    tree_method='hist',         # nhanh hơn nhiều, tối ưu CPU
    random_state=42,
    n_jobs=-1,
    verbosity=0
)

grid_search = GridSearchCV(
    estimator=xgb_model,
    param_grid=param_grid,
    scoring='r2',
    cv=7,                       # hoặc cv=7 nếu muốn kỹ hơn
    verbose=0,                  # không in log
    n_jobs=-1
)